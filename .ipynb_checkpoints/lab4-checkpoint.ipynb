{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 4: Regression Analysis on Diabetes Dataset\n",
        "\n",
        "**Name:** [Your Name]  \n",
        "**Course:** MSCS 634  \n",
        "**Lab Assignment:** Regression Analysis with Linear, Multiple, Polynomial, Ridge, and Lasso Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better visualizations\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "except:\n",
        "    try:\n",
        "        plt.style.use('seaborn')\n",
        "    except:\n",
        "        plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Diabetes dataset\n",
        "diabetes = load_diabetes()\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(f\"Number of samples: {diabetes.data.shape[0]}\")\n",
        "print(f\"Number of features: {diabetes.data.shape[1]}\")\n",
        "print(f\"Feature names: {diabetes.feature_names}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a DataFrame for easier exploration\n",
        "df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
        "df['target'] = diabetes.target\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset Statistics:\")\n",
        "print(df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")\n",
        "print(\"\\nNo missing values found - dataset is clean!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize data distribution\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Target distribution\n",
        "axes[0, 0].hist(df['target'], bins=30, edgecolor='black')\n",
        "axes[0, 0].set_title('Distribution of Target Variable (Disease Progression)')\n",
        "axes[0, 0].set_xlabel('Target Value')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "\n",
        "# Feature distributions\n",
        "axes[0, 1].boxplot([df[col] for col in diabetes.feature_names[:5]], labels=diabetes.feature_names[:5])\n",
        "axes[0, 1].set_title('Boxplot of First 5 Features')\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Correlation heatmap\n",
        "correlation_matrix = df.corr()\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0, ax=axes[1, 0])\n",
        "axes[1, 0].set_title('Correlation Heatmap')\n",
        "\n",
        "# Target vs feature correlation\n",
        "target_corr = df.corr()['target'].sort_values(ascending=False)[:-1]\n",
        "axes[1, 1].barh(range(len(target_corr)), target_corr.values)\n",
        "axes[1, 1].set_yticks(range(len(target_corr)))\n",
        "axes[1, 1].set_yticklabels(target_corr.index)\n",
        "axes[1, 1].set_title('Feature Correlation with Target')\n",
        "axes[1, 1].set_xlabel('Correlation Coefficient')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Linear Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for Simple Linear Regression\n",
        "# Using 'bmi' (Body Mass Index) as it typically has good correlation with health outcomes\n",
        "X_simple = diabetes.data[:, 2].reshape(-1, 1)  # bmi is the 3rd feature (index 2)\n",
        "y = diabetes.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_simple, X_test_simple, y_train, y_test = train_test_split(\n",
        "    X_simple, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {X_train_simple.shape[0]}\")\n",
        "print(f\"Test set size: {X_test_simple.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Simple Linear Regression model\n",
        "simple_lr = LinearRegression()\n",
        "simple_lr.fit(X_train_simple, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred_simple = simple_lr.predict(X_train_simple)\n",
        "y_test_pred_simple = simple_lr.predict(X_test_simple)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "train_mae_simple = mean_absolute_error(y_train, y_train_pred_simple)\n",
        "train_mse_simple = mean_squared_error(y_train, y_train_pred_simple)\n",
        "train_rmse_simple = np.sqrt(train_mse_simple)\n",
        "train_r2_simple = r2_score(y_train, y_train_pred_simple)\n",
        "\n",
        "test_mae_simple = mean_absolute_error(y_test, y_test_pred_simple)\n",
        "test_mse_simple = mean_squared_error(y_test, y_test_pred_simple)\n",
        "test_rmse_simple = np.sqrt(test_mse_simple)\n",
        "test_r2_simple = r2_score(y_test, y_test_pred_simple)\n",
        "\n",
        "print(\"Simple Linear Regression Results:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Training Set Metrics:\")\n",
        "print(f\"  MAE:  {train_mae_simple:.4f}\")\n",
        "print(f\"  MSE:  {train_mse_simple:.4f}\")\n",
        "print(f\"  RMSE: {train_rmse_simple:.4f}\")\n",
        "print(f\"  R²:   {train_r2_simple:.4f}\")\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "print(f\"  MAE:  {test_mae_simple:.4f}\")\n",
        "print(f\"  MSE:  {test_mse_simple:.4f}\")\n",
        "print(f\"  RMSE: {test_rmse_simple:.4f}\")\n",
        "print(f\"  R²:   {test_r2_simple:.4f}\")\n",
        "print(f\"\\nModel Equation: y = {simple_lr.coef_[0]:.4f} * x + {simple_lr.intercept_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Simple Linear Regression\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Training set visualization\n",
        "axes[0].scatter(X_train_simple, y_train, alpha=0.5, label='Actual', color='blue')\n",
        "axes[0].plot(X_train_simple, y_train_pred_simple, color='red', linewidth=2, label='Predicted')\n",
        "axes[0].set_xlabel('BMI (normalized)')\n",
        "axes[0].set_ylabel('Disease Progression')\n",
        "axes[0].set_title(f'Simple Linear Regression - Training Set\\nR² = {train_r2_simple:.4f}')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Test set visualization\n",
        "axes[1].scatter(X_test_simple, y_test, alpha=0.5, label='Actual', color='blue')\n",
        "axes[1].plot(X_test_simple, y_test_pred_simple, color='red', linewidth=2, label='Predicted')\n",
        "axes[1].set_xlabel('BMI (normalized)')\n",
        "axes[1].set_ylabel('Disease Progression')\n",
        "axes[1].set_title(f'Simple Linear Regression - Test Set\\nR² = {test_r2_simple:.4f}')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Multiple Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for Multiple Regression using all features\n",
        "X_multiple = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_multiple, X_test_multiple, y_train_multiple, y_test_multiple = train_test_split(\n",
        "    X_multiple, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {X_train_multiple.shape[0]}\")\n",
        "print(f\"Test set size: {X_test_multiple.shape[0]}\")\n",
        "print(f\"Number of features: {X_train_multiple.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Multiple Regression model\n",
        "multiple_lr = LinearRegression()\n",
        "multiple_lr.fit(X_train_multiple, y_train_multiple)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred_multiple = multiple_lr.predict(X_train_multiple)\n",
        "y_test_pred_multiple = multiple_lr.predict(X_test_multiple)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "train_mae_multiple = mean_absolute_error(y_train_multiple, y_train_pred_multiple)\n",
        "train_mse_multiple = mean_squared_error(y_train_multiple, y_train_pred_multiple)\n",
        "train_rmse_multiple = np.sqrt(train_mse_multiple)\n",
        "train_r2_multiple = r2_score(y_train_multiple, y_train_pred_multiple)\n",
        "\n",
        "test_mae_multiple = mean_absolute_error(y_test_multiple, y_test_pred_multiple)\n",
        "test_mse_multiple = mean_squared_error(y_test_multiple, y_test_pred_multiple)\n",
        "test_rmse_multiple = np.sqrt(test_mse_multiple)\n",
        "test_r2_multiple = r2_score(y_test_multiple, y_test_pred_multiple)\n",
        "\n",
        "print(\"Multiple Regression Results:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Training Set Metrics:\")\n",
        "print(f\"  MAE:  {train_mae_multiple:.4f}\")\n",
        "print(f\"  MSE:  {train_mse_multiple:.4f}\")\n",
        "print(f\"  RMSE: {train_rmse_multiple:.4f}\")\n",
        "print(f\"  R²:   {train_r2_multiple:.4f}\")\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "print(f\"  MAE:  {test_mae_multiple:.4f}\")\n",
        "print(f\"  MSE:  {test_mse_multiple:.4f}\")\n",
        "print(f\"  RMSE: {test_rmse_multiple:.4f}\")\n",
        "print(f\"  R²:   {test_r2_multiple:.4f}\")\n",
        "\n",
        "# Display feature coefficients\n",
        "print(\"\\nFeature Coefficients:\")\n",
        "for i, feature_name in enumerate(diabetes.feature_names):\n",
        "    print(f\"  {feature_name}: {multiple_lr.coef_[i]:.4f}\")\n",
        "print(f\"\\nIntercept: {multiple_lr.intercept_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Multiple Regression predictions\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Training set: Predicted vs Actual\n",
        "axes[0].scatter(y_train_multiple, y_train_pred_multiple, alpha=0.5, color='blue')\n",
        "min_val = min(y_train_multiple.min(), y_train_pred_multiple.min())\n",
        "max_val = max(y_train_multiple.max(), y_train_pred_multiple.max())\n",
        "axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
        "axes[0].set_xlabel('Actual Values')\n",
        "axes[0].set_ylabel('Predicted Values')\n",
        "axes[0].set_title(f'Multiple Regression - Training Set\\nR² = {train_r2_multiple:.4f}')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Test set: Predicted vs Actual\n",
        "axes[1].scatter(y_test_multiple, y_test_pred_multiple, alpha=0.5, color='blue')\n",
        "min_val = min(y_test_multiple.min(), y_test_pred_multiple.min())\n",
        "max_val = max(y_test_multiple.max(), y_test_pred_multiple.max())\n",
        "axes[1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
        "axes[1].set_xlabel('Actual Values')\n",
        "axes[1].set_ylabel('Predicted Values')\n",
        "axes[1].set_title(f'Multiple Regression - Test Set\\nR² = {test_r2_multiple:.4f}')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Polynomial Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for Polynomial Regression\n",
        "# Using 'bmi' feature for polynomial regression\n",
        "X_poly = diabetes.data[:, 2].reshape(-1, 1)  # bmi\n",
        "y = diabetes.target\n",
        "\n",
        "# Split the data\n",
        "X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(\n",
        "    X_poly, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Test different polynomial degrees\n",
        "degrees = [1, 2, 3, 4, 5]\n",
        "poly_results = {}\n",
        "\n",
        "for degree in degrees:\n",
        "    # Create polynomial features\n",
        "    poly_features = PolynomialFeatures(degree=degree)\n",
        "    X_train_poly_transformed = poly_features.fit_transform(X_train_poly)\n",
        "    X_test_poly_transformed = poly_features.transform(X_test_poly)\n",
        "    \n",
        "    # Train model\n",
        "    poly_model = LinearRegression()\n",
        "    poly_model.fit(X_train_poly_transformed, y_train_poly)\n",
        "    \n",
        "    # Make predictions\n",
        "    y_train_pred_poly = poly_model.predict(X_train_poly_transformed)\n",
        "    y_test_pred_poly = poly_model.predict(X_test_poly_transformed)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    train_r2 = r2_score(y_train_poly, y_train_pred_poly)\n",
        "    test_r2 = r2_score(y_test_poly, y_test_pred_poly)\n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train_poly, y_train_pred_poly))\n",
        "    test_rmse = np.sqrt(mean_squared_error(y_test_poly, y_test_pred_poly))\n",
        "    \n",
        "    poly_results[degree] = {\n",
        "        'train_r2': train_r2,\n",
        "        'test_r2': test_r2,\n",
        "        'train_rmse': train_rmse,\n",
        "        'test_rmse': test_rmse,\n",
        "        'model': poly_model,\n",
        "        'poly_features': poly_features\n",
        "    }\n",
        "    \n",
        "    print(f\"Degree {degree}:\")\n",
        "    print(f\"  Train R²: {train_r2:.4f}, Test R²: {test_r2:.4f}\")\n",
        "    print(f\"  Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select degree 2 for detailed analysis (good balance)\n",
        "degree_selected = 2\n",
        "poly_features_selected = poly_results[degree_selected]['poly_features']\n",
        "poly_model_selected = poly_results[degree_selected]['model']\n",
        "\n",
        "X_train_poly_transformed = poly_features_selected.fit_transform(X_train_poly)\n",
        "X_test_poly_transformed = poly_features_selected.transform(X_test_poly)\n",
        "\n",
        "y_train_pred_poly = poly_model_selected.predict(X_train_poly_transformed)\n",
        "y_test_pred_poly = poly_model_selected.predict(X_test_poly_transformed)\n",
        "\n",
        "# Calculate detailed metrics\n",
        "train_mae_poly = mean_absolute_error(y_train_poly, y_train_pred_poly)\n",
        "train_mse_poly = mean_squared_error(y_train_poly, y_train_pred_poly)\n",
        "train_rmse_poly = np.sqrt(train_mse_poly)\n",
        "train_r2_poly = r2_score(y_train_poly, y_train_pred_poly)\n",
        "\n",
        "test_mae_poly = mean_absolute_error(y_test_poly, y_test_pred_poly)\n",
        "test_mse_poly = mean_squared_error(y_test_poly, y_test_pred_poly)\n",
        "test_rmse_poly = np.sqrt(test_mse_poly)\n",
        "test_r2_poly = r2_score(y_test_poly, y_test_pred_poly)\n",
        "\n",
        "print(f\"Polynomial Regression (Degree {degree_selected}) Results:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Training Set Metrics:\")\n",
        "print(f\"  MAE:  {train_mae_poly:.4f}\")\n",
        "print(f\"  MSE:  {train_mse_poly:.4f}\")\n",
        "print(f\"  RMSE: {train_rmse_poly:.4f}\")\n",
        "print(f\"  R²:   {train_r2_poly:.4f}\")\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "print(f\"  MAE:  {test_mae_poly:.4f}\")\n",
        "print(f\"  MSE:  {test_mse_poly:.4f}\")\n",
        "print(f\"  RMSE: {test_rmse_poly:.4f}\")\n",
        "print(f\"  R²:   {test_r2_poly:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Polynomial Regression with different degrees\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "\n",
        "# Plot for each degree\n",
        "for idx, degree in enumerate([1, 2, 3, 4, 5]):\n",
        "    row = idx // 3\n",
        "    col = idx % 3\n",
        "    \n",
        "    poly_features = poly_results[degree]['poly_features']\n",
        "    model = poly_results[degree]['model']\n",
        "    \n",
        "    # Create smooth line for visualization\n",
        "    X_plot = np.linspace(X_train_poly.min(), X_train_poly.max(), 300).reshape(-1, 1)\n",
        "    X_plot_poly = poly_features.transform(X_plot)\n",
        "    y_plot = model.predict(X_plot_poly)\n",
        "    \n",
        "    # Plot\n",
        "    axes[row, col].scatter(X_train_poly, y_train_poly, alpha=0.3, color='blue', label='Training Data')\n",
        "    axes[row, col].scatter(X_test_poly, y_test_poly, alpha=0.3, color='green', label='Test Data')\n",
        "    axes[row, col].plot(X_plot, y_plot, color='red', linewidth=2, label='Polynomial Fit')\n",
        "    axes[row, col].set_xlabel('BMI (normalized)')\n",
        "    axes[row, col].set_ylabel('Disease Progression')\n",
        "    axes[row, col].set_title(f'Degree {degree}\\nTrain R²={poly_results[degree][\"train_r2\"]:.3f}, Test R²={poly_results[degree][\"test_r2\"]:.3f}')\n",
        "    axes[row, col].legend()\n",
        "    axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "# Remove the last subplot\n",
        "axes[1, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare overfitting/underfitting across degrees\n",
        "degrees_list = list(poly_results.keys())\n",
        "train_r2_list = [poly_results[d]['train_r2'] for d in degrees_list]\n",
        "test_r2_list = [poly_results[d]['test_r2'] for d in degrees_list]\n",
        "train_rmse_list = [poly_results[d]['train_rmse'] for d in degrees_list]\n",
        "test_rmse_list = [poly_results[d]['test_rmse'] for d in degrees_list]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# R² comparison\n",
        "axes[0].plot(degrees_list, train_r2_list, 'o-', label='Train R²', linewidth=2, markersize=8)\n",
        "axes[0].plot(degrees_list, test_r2_list, 's-', label='Test R²', linewidth=2, markersize=8)\n",
        "axes[0].set_xlabel('Polynomial Degree')\n",
        "axes[0].set_ylabel('R² Score')\n",
        "axes[0].set_title('R² Score vs Polynomial Degree')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# RMSE comparison\n",
        "axes[1].plot(degrees_list, train_rmse_list, 'o-', label='Train RMSE', linewidth=2, markersize=8)\n",
        "axes[1].plot(degrees_list, test_rmse_list, 's-', label='Test RMSE', linewidth=2, markersize=8)\n",
        "axes[1].set_xlabel('Polynomial Degree')\n",
        "axes[1].set_ylabel('RMSE')\n",
        "axes[1].set_title('RMSE vs Polynomial Degree')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Observations:\")\n",
        "print(\"- Lower degrees (1-2): Better generalization, less overfitting\")\n",
        "print(\"- Higher degrees (4-5): Better training fit but may overfit (gap between train and test)\")\n",
        "print(\"- Degree 2-3 appears to be a good balance\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Regularization with Ridge and Lasso Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for Ridge and Lasso Regression (using all features)\n",
        "X_reg = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "# Split the data\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Test different alpha values\n",
        "alphas = [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
        "ridge_results = {}\n",
        "lasso_results = {}\n",
        "\n",
        "print(\"Testing different alpha values for Ridge and Lasso Regression:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for alpha in alphas:\n",
        "    # Ridge Regression\n",
        "    ridge_model = Ridge(alpha=alpha)\n",
        "    ridge_model.fit(X_train_reg, y_train_reg)\n",
        "    y_train_pred_ridge = ridge_model.predict(X_train_reg)\n",
        "    y_test_pred_ridge = ridge_model.predict(X_test_reg)\n",
        "    \n",
        "    ridge_results[alpha] = {\n",
        "        'train_r2': r2_score(y_train_reg, y_train_pred_ridge),\n",
        "        'test_r2': r2_score(y_test_reg, y_test_pred_ridge),\n",
        "        'train_rmse': np.sqrt(mean_squared_error(y_train_reg, y_train_pred_ridge)),\n",
        "        'test_rmse': np.sqrt(mean_squared_error(y_test_reg, y_test_pred_ridge)),\n",
        "        'model': ridge_model\n",
        "    }\n",
        "    \n",
        "    # Lasso Regression\n",
        "    lasso_model = Lasso(alpha=alpha)\n",
        "    lasso_model.fit(X_train_reg, y_train_reg)\n",
        "    y_train_pred_lasso = lasso_model.predict(X_train_reg)\n",
        "    y_test_pred_lasso = lasso_model.predict(X_test_reg)\n",
        "    \n",
        "    lasso_results[alpha] = {\n",
        "        'train_r2': r2_score(y_train_reg, y_train_pred_lasso),\n",
        "        'test_r2': r2_score(y_test_reg, y_test_pred_lasso),\n",
        "        'train_rmse': np.sqrt(mean_squared_error(y_train_reg, y_train_pred_lasso)),\n",
        "        'test_rmse': np.sqrt(mean_squared_error(y_test_reg, y_test_pred_lasso)),\n",
        "        'model': lasso_model\n",
        "    }\n",
        "    \n",
        "    print(f\"Alpha = {alpha:6.2f} | Ridge Test R²: {ridge_results[alpha]['test_r2']:.4f} | \"\n",
        "          f\"Lasso Test R²: {lasso_results[alpha]['test_r2']:.4f}\")\n",
        "\n",
        "# Select best alpha (alpha=1.0 is often a good default)\n",
        "alpha_selected = 1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Ridge and Lasso with selected alpha\n",
        "ridge_model = Ridge(alpha=alpha_selected)\n",
        "lasso_model = Lasso(alpha=alpha_selected)\n",
        "\n",
        "ridge_model.fit(X_train_reg, y_train_reg)\n",
        "lasso_model.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred_ridge = ridge_model.predict(X_train_reg)\n",
        "y_test_pred_ridge = ridge_model.predict(X_test_reg)\n",
        "y_train_pred_lasso = lasso_model.predict(X_train_reg)\n",
        "y_test_pred_lasso = lasso_model.predict(X_test_reg)\n",
        "\n",
        "# Calculate metrics for Ridge\n",
        "train_mae_ridge = mean_absolute_error(y_train_reg, y_train_pred_ridge)\n",
        "train_mse_ridge = mean_squared_error(y_train_reg, y_train_pred_ridge)\n",
        "train_rmse_ridge = np.sqrt(train_mse_ridge)\n",
        "train_r2_ridge = r2_score(y_train_reg, y_train_pred_ridge)\n",
        "\n",
        "test_mae_ridge = mean_absolute_error(y_test_reg, y_test_pred_ridge)\n",
        "test_mse_ridge = mean_squared_error(y_test_reg, y_test_pred_ridge)\n",
        "test_rmse_ridge = np.sqrt(test_mse_ridge)\n",
        "test_r2_ridge = r2_score(y_test_reg, y_test_pred_ridge)\n",
        "\n",
        "# Calculate metrics for Lasso\n",
        "train_mae_lasso = mean_absolute_error(y_train_reg, y_train_pred_lasso)\n",
        "train_mse_lasso = mean_squared_error(y_train_reg, y_train_pred_lasso)\n",
        "train_rmse_lasso = np.sqrt(train_mse_lasso)\n",
        "train_r2_lasso = r2_score(y_train_reg, y_train_pred_lasso)\n",
        "\n",
        "test_mae_lasso = mean_absolute_error(y_test_reg, y_test_pred_lasso)\n",
        "test_mse_lasso = mean_squared_error(y_test_reg, y_test_pred_lasso)\n",
        "test_rmse_lasso = np.sqrt(test_mse_lasso)\n",
        "test_r2_lasso = r2_score(y_test_reg, y_test_pred_lasso)\n",
        "\n",
        "print(\"Ridge Regression Results (alpha = 1.0):\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Training Set Metrics:\")\n",
        "print(f\"  MAE:  {train_mae_ridge:.4f}\")\n",
        "print(f\"  MSE:  {train_mse_ridge:.4f}\")\n",
        "print(f\"  RMSE: {train_rmse_ridge:.4f}\")\n",
        "print(f\"  R²:   {train_r2_ridge:.4f}\")\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "print(f\"  MAE:  {test_mae_ridge:.4f}\")\n",
        "print(f\"  MSE:  {test_mse_ridge:.4f}\")\n",
        "print(f\"  RMSE: {test_rmse_ridge:.4f}\")\n",
        "print(f\"  R²:   {test_r2_ridge:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Lasso Regression Results (alpha = 1.0):\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Training Set Metrics:\")\n",
        "print(f\"  MAE:  {train_mae_lasso:.4f}\")\n",
        "print(f\"  MSE:  {train_mse_lasso:.4f}\")\n",
        "print(f\"  RMSE: {train_rmse_lasso:.4f}\")\n",
        "print(f\"  R²:   {train_r2_lasso:.4f}\")\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "print(f\"  MAE:  {test_mae_lasso:.4f}\")\n",
        "print(f\"  MSE:  {test_mse_lasso:.4f}\")\n",
        "print(f\"  RMSE: {test_rmse_lasso:.4f}\")\n",
        "print(f\"  R²:   {test_r2_lasso:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare feature coefficients: Multiple Regression vs Ridge vs Lasso\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Multiple Regression coefficients\n",
        "axes[0].barh(range(len(diabetes.feature_names)), multiple_lr.coef_)\n",
        "axes[0].set_yticks(range(len(diabetes.feature_names)))\n",
        "axes[0].set_yticklabels(diabetes.feature_names)\n",
        "axes[0].set_xlabel('Coefficient Value')\n",
        "axes[0].set_title('Multiple Regression\\nCoefficients')\n",
        "axes[0].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Ridge coefficients\n",
        "axes[1].barh(range(len(diabetes.feature_names)), ridge_model.coef_)\n",
        "axes[1].set_yticks(range(len(diabetes.feature_names)))\n",
        "axes[1].set_yticklabels(diabetes.feature_names)\n",
        "axes[1].set_xlabel('Coefficient Value')\n",
        "axes[1].set_title(f'Ridge Regression (α={alpha_selected})\\nCoefficients (Shrunk)')\n",
        "axes[1].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Lasso coefficients\n",
        "axes[2].barh(range(len(diabetes.feature_names)), lasso_model.coef_)\n",
        "axes[2].set_yticks(range(len(diabetes.feature_names)))\n",
        "axes[2].set_yticklabels(diabetes.feature_names)\n",
        "axes[2].set_xlabel('Coefficient Value')\n",
        "axes[2].set_title(f'Lasso Regression (α={alpha_selected})\\nCoefficients (Some Zeroed)')\n",
        "axes[2].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Count non-zero coefficients in Lasso\n",
        "non_zero_lasso = np.sum(lasso_model.coef_ != 0)\n",
        "print(f\"\\nLasso Regression: {non_zero_lasso} out of {len(diabetes.feature_names)} features have non-zero coefficients\")\n",
        "print(\"Features with zero coefficients (removed by Lasso):\")\n",
        "for i, name in enumerate(diabetes.feature_names):\n",
        "    if lasso_model.coef_[i] == 0:\n",
        "        print(f\"  - {name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize how alpha affects Ridge and Lasso\n",
        "alphas_list = list(ridge_results.keys())\n",
        "ridge_test_r2 = [ridge_results[a]['test_r2'] for a in alphas_list]\n",
        "lasso_test_r2 = [lasso_results[a]['test_r2'] for a in alphas_list]\n",
        "ridge_test_rmse = [ridge_results[a]['test_rmse'] for a in alphas_list]\n",
        "lasso_test_rmse = [lasso_results[a]['test_rmse'] for a in alphas_list]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# R² comparison\n",
        "axes[0].semilogx(alphas_list, ridge_test_r2, 'o-', label='Ridge', linewidth=2, markersize=8)\n",
        "axes[0].semilogx(alphas_list, lasso_test_r2, 's-', label='Lasso', linewidth=2, markersize=8)\n",
        "axes[0].set_xlabel('Alpha (Regularization Parameter)')\n",
        "axes[0].set_ylabel('Test R² Score')\n",
        "axes[0].set_title('Test R² vs Alpha (Regularization Parameter)')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# RMSE comparison\n",
        "axes[1].semilogx(alphas_list, ridge_test_rmse, 'o-', label='Ridge', linewidth=2, markersize=8)\n",
        "axes[1].semilogx(alphas_list, lasso_test_rmse, 's-', label='Lasso', linewidth=2, markersize=8)\n",
        "axes[1].set_xlabel('Alpha (Regularization Parameter)')\n",
        "axes[1].set_ylabel('Test RMSE')\n",
        "axes[1].set_title('Test RMSE vs Alpha (Regularization Parameter)')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Observations about Regularization:\")\n",
        "print(\"- Low alpha (0.01-0.1): Less regularization, models behave more like Multiple Regression\")\n",
        "print(\"- Medium alpha (1.0-10.0): Balanced regularization, prevents overfitting\")\n",
        "print(\"- High alpha (100-1000): Too much regularization, underfitting occurs\")\n",
        "print(\"- Lasso can zero out features (feature selection), while Ridge shrinks all features\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions: Ridge vs Lasso\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Ridge - Training\n",
        "axes[0, 0].scatter(y_train_reg, y_train_pred_ridge, alpha=0.5, color='blue')\n",
        "min_val = min(y_train_reg.min(), y_train_pred_ridge.min())\n",
        "max_val = max(y_train_reg.max(), y_train_pred_ridge.max())\n",
        "axes[0, 0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
        "axes[0, 0].set_xlabel('Actual Values')\n",
        "axes[0, 0].set_ylabel('Predicted Values')\n",
        "axes[0, 0].set_title(f'Ridge Regression - Training Set\\nR² = {train_r2_ridge:.4f}')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Ridge - Test\n",
        "axes[0, 1].scatter(y_test_reg, y_test_pred_ridge, alpha=0.5, color='blue')\n",
        "min_val = min(y_test_reg.min(), y_test_pred_ridge.min())\n",
        "max_val = max(y_test_reg.max(), y_test_pred_ridge.max())\n",
        "axes[0, 1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
        "axes[0, 1].set_xlabel('Actual Values')\n",
        "axes[0, 1].set_ylabel('Predicted Values')\n",
        "axes[0, 1].set_title(f'Ridge Regression - Test Set\\nR² = {test_r2_ridge:.4f}')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Lasso - Training\n",
        "axes[1, 0].scatter(y_train_reg, y_train_pred_lasso, alpha=0.5, color='green')\n",
        "min_val = min(y_train_reg.min(), y_train_pred_lasso.min())\n",
        "max_val = max(y_train_reg.max(), y_train_pred_lasso.max())\n",
        "axes[1, 0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
        "axes[1, 0].set_xlabel('Actual Values')\n",
        "axes[1, 0].set_ylabel('Predicted Values')\n",
        "axes[1, 0].set_title(f'Lasso Regression - Training Set\\nR² = {train_r2_lasso:.4f}')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Lasso - Test\n",
        "axes[1, 1].scatter(y_test_reg, y_test_pred_lasso, alpha=0.5, color='green')\n",
        "min_val = min(y_test_reg.min(), y_test_pred_lasso.min())\n",
        "max_val = max(y_test_reg.max(), y_test_pred_lasso.max())\n",
        "axes[1, 1].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
        "axes[1, 1].set_xlabel('Actual Values')\n",
        "axes[1, 1].set_ylabel('Predicted Values')\n",
        "axes[1, 1].set_title(f'Lasso Regression - Test Set\\nR² = {test_r2_lasso:.4f}')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Model Comparison and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a comprehensive comparison table\n",
        "comparison_data = {\n",
        "    'Model': [\n",
        "        'Simple Linear Regression',\n",
        "        'Multiple Regression',\n",
        "        'Polynomial Regression (deg=2)',\n",
        "        'Ridge Regression (α=1.0)',\n",
        "        'Lasso Regression (α=1.0)'\n",
        "    ],\n",
        "    'Train MAE': [\n",
        "        train_mae_simple,\n",
        "        train_mae_multiple,\n",
        "        train_mae_poly,\n",
        "        train_mae_ridge,\n",
        "        train_mae_lasso\n",
        "    ],\n",
        "    'Test MAE': [\n",
        "        test_mae_simple,\n",
        "        test_mae_multiple,\n",
        "        test_mae_poly,\n",
        "        test_mae_ridge,\n",
        "        test_mae_lasso\n",
        "    ],\n",
        "    'Train RMSE': [\n",
        "        train_rmse_simple,\n",
        "        train_rmse_multiple,\n",
        "        train_rmse_poly,\n",
        "        train_rmse_ridge,\n",
        "        train_rmse_lasso\n",
        "    ],\n",
        "    'Test RMSE': [\n",
        "        test_rmse_simple,\n",
        "        test_rmse_multiple,\n",
        "        test_rmse_poly,\n",
        "        test_rmse_ridge,\n",
        "        test_rmse_lasso\n",
        "    ],\n",
        "    'Train R²': [\n",
        "        train_r2_simple,\n",
        "        train_r2_multiple,\n",
        "        train_r2_poly,\n",
        "        train_r2_ridge,\n",
        "        train_r2_lasso\n",
        "    ],\n",
        "    'Test R²': [\n",
        "        test_r2_simple,\n",
        "        test_r2_multiple,\n",
        "        test_r2_poly,\n",
        "        test_r2_ridge,\n",
        "        test_r2_lasso\n",
        "    ]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"Model Performance Comparison:\")\n",
        "print(\"=\" * 100)\n",
        "print(comparison_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize model comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "models = comparison_df['Model'].values\n",
        "x_pos = np.arange(len(models))\n",
        "\n",
        "# Test R² comparison\n",
        "axes[0, 0].bar(x_pos, comparison_df['Test R²'], color=['blue', 'green', 'orange', 'red', 'purple'], alpha=0.7)\n",
        "axes[0, 0].set_xticks(x_pos)\n",
        "axes[0, 0].set_xticklabels(models, rotation=45, ha='right')\n",
        "axes[0, 0].set_ylabel('R² Score')\n",
        "axes[0, 0].set_title('Test R² Score Comparison')\n",
        "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
        "axes[0, 0].set_ylim([0, max(comparison_df['Test R²']) * 1.1])\n",
        "\n",
        "# Test RMSE comparison\n",
        "axes[0, 1].bar(x_pos, comparison_df['Test RMSE'], color=['blue', 'green', 'orange', 'red', 'purple'], alpha=0.7)\n",
        "axes[0, 1].set_xticks(x_pos)\n",
        "axes[0, 1].set_xticklabels(models, rotation=45, ha='right')\n",
        "axes[0, 1].set_ylabel('RMSE')\n",
        "axes[0, 1].set_title('Test RMSE Comparison (Lower is Better)')\n",
        "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Train vs Test R²\n",
        "axes[1, 0].bar(x_pos - 0.2, comparison_df['Train R²'], width=0.4, label='Train R²', alpha=0.7)\n",
        "axes[1, 0].bar(x_pos + 0.2, comparison_df['Test R²'], width=0.4, label='Test R²', alpha=0.7)\n",
        "axes[1, 0].set_xticks(x_pos)\n",
        "axes[1, 0].set_xticklabels(models, rotation=45, ha='right')\n",
        "axes[1, 0].set_ylabel('R² Score')\n",
        "axes[1, 0].set_title('Train vs Test R² Comparison')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Train vs Test RMSE\n",
        "axes[1, 1].bar(x_pos - 0.2, comparison_df['Train RMSE'], width=0.4, label='Train RMSE', alpha=0.7)\n",
        "axes[1, 1].bar(x_pos + 0.2, comparison_df['Test RMSE'], width=0.4, label='Test RMSE', alpha=0.7)\n",
        "axes[1, 1].set_xticks(x_pos)\n",
        "axes[1, 1].set_xticklabels(models, rotation=45, ha='right')\n",
        "axes[1, 1].set_ylabel('RMSE')\n",
        "axes[1, 1].set_title('Train vs Test RMSE Comparison')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Key Observations and Analysis\n",
        "\n",
        "#### 1. Model Performance Summary\n",
        "\n",
        "**Simple Linear Regression:**\n",
        "- Uses only one feature (BMI), making it the simplest model\n",
        "- Lower R² score compared to models using multiple features\n",
        "- Good baseline for comparison\n",
        "- Limited predictive power due to using only one feature\n",
        "\n",
        "**Multiple Regression:**\n",
        "- Uses all available features, capturing more information\n",
        "- Significantly better performance than Simple Linear Regression\n",
        "- Higher R² score indicates better fit\n",
        "- May be prone to overfitting if not regularized\n",
        "\n",
        "**Polynomial Regression:**\n",
        "- Captures non-linear relationships in the data\n",
        "- Degree 2 provides a good balance between complexity and generalization\n",
        "- Higher degrees can lead to overfitting (large gap between train and test performance)\n",
        "- Useful when relationships are non-linear\n",
        "\n",
        "**Ridge Regression:**\n",
        "- Adds L2 regularization to prevent overfitting\n",
        "- Shrinks all coefficients but doesn't eliminate any features\n",
        "- Helps with multicollinearity issues\n",
        "- Performance similar to Multiple Regression but more stable\n",
        "\n",
        "**Lasso Regression:**\n",
        "- Adds L1 regularization with feature selection capability\n",
        "- Can zero out less important features\n",
        "- Useful for feature selection and model interpretability\n",
        "- May perform slightly worse if all features are important\n",
        "\n",
        "#### 2. Overfitting and Underfitting Analysis\n",
        "\n",
        "- **Simple Linear Regression**: May underfit due to limited complexity\n",
        "- **Multiple Regression**: Risk of overfitting, especially with many features\n",
        "- **Polynomial Regression**: Higher degrees show clear overfitting (large train-test gap)\n",
        "- **Ridge Regression**: Regularization helps prevent overfitting\n",
        "- **Lasso Regression**: Regularization + feature selection helps with overfitting\n",
        "\n",
        "#### 3. Insights about the Diabetes Dataset\n",
        "\n",
        "- Multiple features contribute to disease progression prediction\n",
        "- Non-linear relationships exist (Polynomial Regression improves over Simple Linear)\n",
        "- Regularization helps stabilize predictions\n",
        "- Feature selection (Lasso) can identify most important predictors\n",
        "- The dataset benefits from using all features rather than just one\n",
        "\n",
        "#### 4. Recommendations\n",
        "\n",
        "1. **For best performance**: Use Multiple Regression or Ridge Regression\n",
        "2. **For interpretability**: Use Lasso Regression to identify key features\n",
        "3. **For non-linear relationships**: Use Polynomial Regression with degree 2-3\n",
        "4. **For simplicity**: Simple Linear Regression provides a baseline but limited accuracy\n",
        "\n",
        "#### 5. Regularization Parameter (Alpha) Impact\n",
        "\n",
        "- **Low alpha (0.01-0.1)**: Models behave like Multiple Regression, minimal regularization\n",
        "- **Medium alpha (1.0-10.0)**: Balanced regularization, prevents overfitting effectively\n",
        "- **High alpha (100-1000)**: Too much regularization leads to underfitting\n",
        "- **Lasso vs Ridge**: Lasso performs feature selection (zeros out features), Ridge shrinks all features\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
